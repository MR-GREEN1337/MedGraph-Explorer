{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:08.248927Z",
     "iopub.status.busy": "2025-03-05T19:27:08.248583Z",
     "iopub.status.idle": "2025-03-05T19:27:11.633641Z",
     "shell.execute_reply": "2025-03-05T19:27:11.632612Z",
     "shell.execute_reply.started": "2025-03-05T19:27:08.248884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install nx-arangodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:11.635189Z",
     "iopub.status.busy": "2025-03-05T19:27:11.634939Z",
     "iopub.status.idle": "2025-03-05T19:27:11.817228Z",
     "shell.execute_reply": "2025-03-05T19:27:11.816185Z",
     "shell.execute_reply.started": "2025-03-05T19:27:11.635158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:11.819182Z",
     "iopub.status.busy": "2025-03-05T19:27:11.818896Z",
     "iopub.status.idle": "2025-03-05T19:27:15.196844Z",
     "shell.execute_reply": "2025-03-05T19:27:15.195937Z",
     "shell.execute_reply.started": "2025-03-05T19:27:11.819158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:15.198601Z",
     "iopub.status.busy": "2025-03-05T19:27:15.198275Z",
     "iopub.status.idle": "2025-03-05T19:27:19.379909Z",
     "shell.execute_reply": "2025-03-05T19:27:19.379004Z",
     "shell.execute_reply.started": "2025-03-05T19:27:15.198567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade langchain langchain-community langchain-openai langgraph arango-datasets kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:19.381299Z",
     "iopub.status.busy": "2025-03-05T19:27:19.381020Z",
     "iopub.status.idle": "2025-03-05T19:27:19.386812Z",
     "shell.execute_reply": "2025-03-05T19:27:19.385939Z",
     "shell.execute_reply.started": "2025-03-05T19:27:19.381274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Import the required modules\n",
    "\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "\n",
    "from arango import ArangoClient\n",
    "from arango_datasets import Datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import re\n",
    "import json\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:27:19.387828Z",
     "iopub.status.busy": "2025-03-05T19:27:19.387567Z",
     "iopub.status.idle": "2025-03-05T19:28:46.164011Z",
     "shell.execute_reply": "2025-03-05T19:28:46.163085Z",
     "shell.execute_reply.started": "2025-03-05T19:27:19.387807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "db = ArangoClient(hosts=\"https://...arangodb.cloud:...\").db(username=\"root\", password=\"...\", verify=True)\n",
    "\n",
    "datasets = Datasets(db)\n",
    "\n",
    "print(datasets.dataset_info(\"SYNTHEA_P100\"))\n",
    "\n",
    "datasets.load(\"SYNTHEA_P100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:28:46.165298Z",
     "iopub.status.busy": "2025-03-05T19:28:46.164975Z",
     "iopub.status.idle": "2025-03-05T19:28:47.156872Z",
     "shell.execute_reply": "2025-03-05T19:28:47.156020Z",
     "shell.execute_reply.started": "2025-03-05T19:28:46.165268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "llm.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:28:47.160043Z",
     "iopub.status.busy": "2025-03-05T19:28:47.159793Z",
     "iopub.status.idle": "2025-03-05T19:28:47.404236Z",
     "shell.execute_reply": "2025-03-05T19:28:47.398859Z",
     "shell.execute_reply.started": "2025-03-05T19:28:47.160020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "G_adb = nxadb.Graph(name=\"SYNTHEA_P100\", db=db)\n",
    "print(f\"Graph loaded with {len(G_adb.nodes)} nodes and {len(G_adb.edges)} edges\")\n",
    "\n",
    "# Optional: try to init cuGraph for GPU acceleration\n",
    "try:\n",
    "    import nx_cugraph as nxcg\n",
    "    G_cugraph = nxcg.Graph(G_adb)\n",
    "    use_gpu = True\n",
    "    print(\"GPU acceleration enabled via cuGraph\")\n",
    "except Exception as e:\n",
    "    use_gpu = False\n",
    "    print(f\"GPU acceleration not available: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:29:58.216731Z",
     "iopub.status.busy": "2025-03-05T19:29:58.216424Z",
     "iopub.status.idle": "2025-03-05T19:29:58.227326Z",
     "shell.execute_reply": "2025-03-05T19:29:58.226294Z",
     "shell.execute_reply.started": "2025-03-05T19:29:58.216708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def query_medical_graph(query_spec: dict):\n",
    "    \"\"\"\n",
    "    Dynamic medical graph analysis tool that determines the optimal query technique\n",
    "    and executes it. Supports AQL, NetworkX/cuGraph algorithms, or hybrid approaches.\n",
    "    \n",
    "    Parameters:\n",
    "    - query_spec: A dictionary containing:\n",
    "      - query: Natural language query about medical data\n",
    "      - context: Optional additional context\n",
    "      - parameters: Optional specific query parameters\n",
    "      - approach: Optional preferred analysis method\n",
    "    \"\"\"\n",
    "    # Extract query components\n",
    "    query = query_spec['query']\n",
    "    context = query_spec.get('context', {})\n",
    "    parameters = query_spec.get('parameters', {})\n",
    "    approach = query_spec.get('approach', None)\n",
    "    \n",
    "    # Analyze query intent to determine approach\n",
    "    query_analysis = llm.invoke(f\"\"\"\n",
    "    Analyze this medical query intent: \"{query}\"\n",
    "    \n",
    "    Classify this query into one of the following categories:\n",
    "    1. SIMPLE_RELATIONSHIP - Direct lookups, basic traversals, simple filtering\n",
    "    2. COMPLEX_PATTERN - Requires graph algorithms (centrality, community detection, path analysis)\n",
    "    3. HYBRID - Requires both relationship data and complex graph analytics\n",
    "    \n",
    "    Return classification in JSON:\n",
    "    {{\n",
    "        \"category\": \"SIMPLE_RELATIONSHIP|COMPLEX_PATTERN|HYBRID\",\n",
    "        \"explanation\": \"Brief explanation why\",\n",
    "        \"suggested_approach\": \"AQL|NetworkX|Hybrid\"\n",
    "    }}\n",
    "    \n",
    "    Context: {context if context else \"No additional context provided\"}\n",
    "    \"\"\").content\n",
    "    \n",
    "    # Extract analysis results\n",
    "    try:\n",
    "        analysis_result = json.loads(re.search(r'\\{.*\\}', query_analysis, re.DOTALL).group())\n",
    "        query_category = analysis_result.get('category', 'SIMPLE_RELATIONSHIP')\n",
    "        suggested_approach = analysis_result.get('suggested_approach', 'AQL')\n",
    "    except:\n",
    "        query_category = 'SIMPLE_RELATIONSHIP'\n",
    "        suggested_approach = 'AQL'\n",
    "    \n",
    "    # Override with specified approach if provided\n",
    "    if approach:\n",
    "        suggested_approach = approach\n",
    "    \n",
    "    # Execute appropriate query technique\n",
    "    if suggested_approach == 'AQL' or query_category == 'SIMPLE_RELATIONSHIP':\n",
    "        return execute_aql_query(query, parameters, context)\n",
    "    elif suggested_approach == 'NetworkX' or query_category == 'COMPLEX_PATTERN':\n",
    "        return execute_networkx_query(query, parameters, context)\n",
    "    else:  # Hybrid approach\n",
    "        return execute_hybrid_query(query, parameters, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:20.192001Z",
     "iopub.status.busy": "2025-03-05T19:30:20.191657Z",
     "iopub.status.idle": "2025-03-05T19:30:20.205173Z",
     "shell.execute_reply": "2025-03-05T19:30:20.204227Z",
     "shell.execute_reply.started": "2025-03-05T19:30:20.191973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def execute_aql_query(query, parameters={}, context={}):\n",
    "    \"\"\"Execute AQL queries via LangChain for simple relationship queries\"\"\"\n",
    "    chain = ArangoGraphQAChain.from_llm(\n",
    "        llm=llm,\n",
    "        graph=arango_graph,\n",
    "        verbose=True,\n",
    "        allow_dangerous_requests=True\n",
    "    )\n",
    "    \n",
    "    # Enhance query with medical context\n",
    "    enhanced_query = f\"\"\"\n",
    "    Based on the Synthea medical knowledge graph:\n",
    "    \n",
    "    Original query: {query}\n",
    "    \n",
    "    Additional context: {context if context else \"None\"}\n",
    "    \n",
    "    Parameters to consider: {parameters if parameters else \"None\"}\n",
    "    \"\"\"\n",
    "    \n",
    "    result = chain.invoke(enhanced_query)\n",
    "    \n",
    "    # Structure and analyze results\n",
    "    analysis = llm.invoke(f\"\"\"\n",
    "    Based on this query result from a medical database:\n",
    "    \n",
    "    {result['result']}\n",
    "    \n",
    "    Extract and structure the key information in a format useful for medical analysis.\n",
    "    Focus on presenting clear, structured data highlighting any potential rare disease insights.\n",
    "    \n",
    "    Return a structured JSON with relevant medical fields.\n",
    "    \"\"\").content\n",
    "    \n",
    "    try:\n",
    "        structured_data = json.loads(re.search(r'\\{.*\\}', analysis, re.DOTALL).group())\n",
    "        return {\n",
    "            \"result\": result['result'],\n",
    "            \"structured_data\": structured_data,\n",
    "            \"query_type\": \"AQL\",\n",
    "            \"original_query\": query\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            \"result\": result['result'],\n",
    "            \"query_type\": \"AQL\",\n",
    "            \"original_query\": query\n",
    "        }\n",
    "\n",
    "def execute_networkx_query(query, parameters={}, context={}):\n",
    "    \"\"\"Execute NetworkX/cuGraph algorithms for complex pattern analysis\"\"\"\n",
    "    # Generate appropriate NetworkX/cuGraph code\n",
    "    code_generation_prompt = f\"\"\"\n",
    "    I have a NetworkX Graph `G_adb` representing a medical knowledge graph from Synthea.\n",
    "    \n",
    "    The query is: \"{query}\"\n",
    "    \n",
    "    Additional context: {context if context else \"None\"}\n",
    "    Parameters: {parameters if parameters else \"None\"}\n",
    "    \n",
    "    Generate Python code using NetworkX and/or cuGraph algorithms to answer this query.\n",
    "    Focus on detecting rare disease patterns, unusual symptom clusters, or atypical progressions.\n",
    "    \n",
    "    Your code should:\n",
    "    1. Extract relevant subgraph if needed\n",
    "    2. Apply appropriate graph algorithms (centrality, community detection, path analysis)\n",
    "    3. Interpret results for rare disease analysis\n",
    "    4. Store final answer in variable FINAL_RESULT\n",
    "    \n",
    "    Only provide executable Python code without explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    nx_code = llm.invoke(code_generation_prompt).content\n",
    "    nx_code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", nx_code, flags=re.MULTILINE).strip()\n",
    "    \n",
    "    # Try to use GPU acceleration when available\n",
    "    try:\n",
    "        if use_gpu:\n",
    "            global_vars = {\"G_adb\": G_adb, \"G_cugraph\": G_cugraph, \"nx\": nx, \"nxcg\": nxcg, \"db\": db}\n",
    "        else:\n",
    "            global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"db\": db}\n",
    "        \n",
    "        local_vars = {}\n",
    "        exec(nx_code_cleaned, global_vars, local_vars)\n",
    "        result = local_vars.get(\"FINAL_RESULT\", \"No result was generated\")\n",
    "    except Exception as e:\n",
    "        # Try to fix common errors\n",
    "        fix_prompt = f\"\"\"\n",
    "        The following NetworkX code failed with error: {str(e)}\n",
    "        \n",
    "        Code:\n",
    "        {nx_code_cleaned}\n",
    "        \n",
    "        Please fix the code to address this error. Focus only on fixing the error.\n",
    "        \"\"\"\n",
    "        \n",
    "        fixed_code = llm.invoke(fix_prompt).content\n",
    "        fixed_code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", fixed_code, flags=re.MULTILINE).strip()\n",
    "        \n",
    "        try:\n",
    "            exec(fixed_code_cleaned, global_vars, local_vars)\n",
    "            result = local_vars.get(\"FINAL_RESULT\", \"No result was generated after fixing code\")\n",
    "        except Exception as e2:\n",
    "            return {\n",
    "                \"error\": f\"Graph analysis failed: {str(e2)}\",\n",
    "                \"query_type\": \"NetworkX\",\n",
    "                \"original_query\": query\n",
    "            }\n",
    "    \n",
    "    # Enhance the result with medical interpretation\n",
    "    result_interpretation = llm.invoke(f\"\"\"\n",
    "    I executed graph analytics on a medical knowledge graph to answer: \"{query}\"\n",
    "    \n",
    "    The analysis result is: {result}\n",
    "    \n",
    "    Please interpret this result in the context of rare disease diagnosis, explaining:\n",
    "    1. What patterns or insights were found\n",
    "    2. How these relate to potential rare disease diagnosis\n",
    "    3. Clinical significance of these findings\n",
    "    \n",
    "    Return your interpretation in a structured JSON format with medical insights.\n",
    "    \"\"\").content\n",
    "    \n",
    "    try:\n",
    "        interpretation_data = json.loads(re.search(r'\\{.*\\}', result_interpretation, re.DOTALL).group())\n",
    "        return {\n",
    "            \"result\": result,\n",
    "            \"interpretation\": interpretation_data,\n",
    "            \"query_type\": \"NetworkX\",\n",
    "            \"original_query\": query\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            \"result\": result,\n",
    "            \"interpretation\": result_interpretation,\n",
    "            \"query_type\": \"NetworkX\",\n",
    "            \"original_query\": query\n",
    "        }\n",
    "\n",
    "def execute_hybrid_query(query, parameters={}, context={}):\n",
    "    \"\"\"Execute hybrid queries combining AQL and NetworkX for complex analysis\"\"\"\n",
    "    # Determine what parts need AQL vs NetworkX\n",
    "    query_decomposition = llm.invoke(f\"\"\"\n",
    "    I need to analyze this medical query using a hybrid approach combining AQL and NetworkX:\n",
    "    \n",
    "    \"{query}\"\n",
    "    \n",
    "    Break this query into components that should be handled by:\n",
    "    1. AQL - for retrieving specific data relationships\n",
    "    2. NetworkX - for complex pattern analysis\n",
    "    \n",
    "    Provide decomposition in JSON format:\n",
    "    {{\n",
    "        \"aql_component\": \"What specific data should be retrieved using AQL\",\n",
    "        \"networkx_component\": \"What analysis should be performed using NetworkX\",\n",
    "        \"integration_strategy\": \"How to combine the results\"\n",
    "    }}\n",
    "    \"\"\").content\n",
    "    \n",
    "    try:\n",
    "        decomposition = json.loads(re.search(r'\\{.*\\}', query_decomposition, re.DOTALL).group())\n",
    "        aql_component = decomposition.get('aql_component', '')\n",
    "        networkx_component = decomposition.get('networkx_component', '')\n",
    "        integration_strategy = decomposition.get('integration_strategy', '')\n",
    "    except:\n",
    "        # Default decomposition if parsing fails\n",
    "        aql_component = f\"Retrieve relevant data for: {query}\"\n",
    "        networkx_component = f\"Analyze patterns in the data for: {query}\"\n",
    "        integration_strategy = \"Combine the results to provide insights\"\n",
    "    \n",
    "    # Step 1: Execute AQL query to get base data\n",
    "    aql_result = execute_aql_query(aql_component, parameters, context)\n",
    "    \n",
    "    # Step 2: Prepare NetworkX analysis with context from AQL results\n",
    "    enhanced_context = {\n",
    "        **context,\n",
    "        \"aql_results\": aql_result.get(\"result\", \"\")\n",
    "    }\n",
    "    \n",
    "    # Step 3: Execute NetworkX analysis\n",
    "    networkx_result = execute_networkx_query(networkx_component, parameters, enhanced_context)\n",
    "    \n",
    "    # Step 4: Integrate results\n",
    "    integration_prompt = f\"\"\"\n",
    "    I executed a hybrid analysis on a medical knowledge graph using both AQL and NetworkX:\n",
    "    \n",
    "    Original query: \"{query}\"\n",
    "    \n",
    "    AQL component result: {aql_result.get('result', '')}\n",
    "    \n",
    "    NetworkX component result: {networkx_result.get('result', '')}\n",
    "    \n",
    "    Integration strategy: {integration_strategy}\n",
    "    \n",
    "    Please integrate these results to provide a comprehensive answer.\n",
    "    Focus on insights related to rare disease patterns, unusual symptoms, or diagnostic pathways.\n",
    "    \n",
    "    Return your integrated analysis in a structured JSON format with medical insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    integrated_result = llm.invoke(integration_prompt).content\n",
    "    \n",
    "    try:\n",
    "        integrated_data = json.loads(re.search(r'\\{.*\\}', integrated_result, re.DOTALL).group())\n",
    "        return {\n",
    "            \"result\": integrated_result,\n",
    "            \"structured_data\": integrated_data,\n",
    "            \"aql_component\": aql_result,\n",
    "            \"networkx_component\": networkx_result,\n",
    "            \"query_type\": \"Hybrid\",\n",
    "            \"original_query\": query\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            \"result\": integrated_result,\n",
    "            \"aql_component\": aql_result,\n",
    "            \"networkx_component\": networkx_result,\n",
    "            \"query_type\": \"Hybrid\",\n",
    "            \"original_query\": query\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:23.572781Z",
     "iopub.status.busy": "2025-03-05T19:30:23.572471Z",
     "iopub.status.idle": "2025-03-05T19:30:23.592486Z",
     "shell.execute_reply": "2025-03-05T19:30:23.591635Z",
     "shell.execute_reply.started": "2025-03-05T19:30:23.572756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def analyze_patient_symptoms(patient_spec: dict):\n",
    "    \"\"\"\n",
    "    Advanced patient symptom analyzer for rare disease identification.\n",
    "    \n",
    "    Parameters:\n",
    "    - patient_spec: A dictionary containing:\n",
    "      - patient_id: Optional patient ID\n",
    "      - symptoms: Optional list of symptoms to analyze\n",
    "      - metadata: Optional additional information\n",
    "      - analysis_type: Analysis type (\"rare_disease\", \"evidence_path\", \n",
    "                       \"similar_cases\", \"progression\")\n",
    "    \"\"\"\n",
    "    # Extract patient specification\n",
    "    patient_id = patient_spec.get('patient_id')\n",
    "    symptoms = patient_spec.get('symptoms', [])\n",
    "    metadata = patient_spec.get('metadata', {})\n",
    "    analysis_type = patient_spec.get('analysis_type', 'rare_disease')\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Symptom-based analysis (no patient ID)\n",
    "    if not patient_id and symptoms:\n",
    "        # Convert symptoms to codes if needed\n",
    "        symptom_codes = []\n",
    "        for symptom in symptoms:\n",
    "            if not str(symptom).isdigit():\n",
    "                # Find SNOMED codes for symptom descriptions\n",
    "                aql_query = f\"\"\"\n",
    "                FOR obs IN observations\n",
    "                    FILTER LOWER(obs.DESCRIPTION) LIKE LOWER(\"%{symptom}%\")\n",
    "                    RETURN DISTINCT obs.CODE\n",
    "                \"\"\"\n",
    "                cursor = db.aql.execute(aql_query)\n",
    "                codes = [doc for doc in cursor]\n",
    "                if codes:\n",
    "                    symptom_codes.extend(codes)\n",
    "            else:\n",
    "                symptom_codes.append(symptom)\n",
    "        \n",
    "        # Find rare conditions associated with these symptoms\n",
    "        aql_query = f\"\"\"\n",
    "        LET symptom_codes = {symptom_codes}\n",
    "        \n",
    "        // Find patients with these symptoms\n",
    "        LET patients_with_symptoms = (\n",
    "            FOR obs IN observations\n",
    "                FILTER obs.CODE IN symptom_codes\n",
    "                RETURN DISTINCT obs.PATIENT\n",
    "        )\n",
    "        \n",
    "        // Find conditions these patients have\n",
    "        LET conditions = (\n",
    "            FOR patient IN patients_with_symptoms\n",
    "                FOR cond IN conditions\n",
    "                    FILTER cond.PATIENT == patient\n",
    "                    COLLECT code = cond.CODE, description = cond.DESCRIPTION\n",
    "                    WITH COUNT INTO count\n",
    "                    SORT count ASC\n",
    "                    RETURN {{\n",
    "                        code: code,\n",
    "                        description: description,\n",
    "                        patient_count: count,\n",
    "                        prevalence: count / LENGTH(patients_with_symptoms)\n",
    "                    }}\n",
    "        )\n",
    "        \n",
    "        // Return relatively rare conditions\n",
    "        FOR cond IN conditions\n",
    "            FILTER cond.patient_count <= 0.1 * LENGTH(patients_with_symptoms)\n",
    "            SORT cond.patient_count ASC\n",
    "            LIMIT 10\n",
    "            RETURN cond\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor = db.aql.execute(aql_query)\n",
    "        results[\"potential_rare_conditions\"] = [doc for doc in cursor]\n",
    "        results[\"symptom_analysis\"] = {\n",
    "            \"input_symptoms\": symptoms,\n",
    "            \"symptom_codes_identified\": symptom_codes,\n",
    "            \"analysis_type\": \"symptom-based\"\n",
    "        }\n",
    "    \n",
    "    # Patient ID-based analysis\n",
    "    elif patient_id:\n",
    "        # Get patient observations\n",
    "        aql_query = f\"\"\"\n",
    "        FOR obs IN observations\n",
    "            FILTER obs.PATIENT == \"{patient_id}\"\n",
    "            SORT obs.DATE\n",
    "            RETURN {{\n",
    "                code: obs.CODE,\n",
    "                description: obs.DESCRIPTION,\n",
    "                date: obs.DATE,\n",
    "                value: obs.VALUE\n",
    "            }}\n",
    "        \"\"\"\n",
    "        cursor = db.aql.execute(aql_query)\n",
    "        patient_observations = [doc for doc in cursor]\n",
    "        \n",
    "        # Get patient conditions\n",
    "        aql_query = f\"\"\"\n",
    "        FOR c IN conditions\n",
    "            FILTER c.PATIENT == \"{patient_id}\"\n",
    "            RETURN {{\n",
    "                code: c.CODE,\n",
    "                description: c.DESCRIPTION,\n",
    "                start: c.START,\n",
    "                stop: c.STOP\n",
    "            }}\n",
    "        \"\"\"\n",
    "        cursor = db.aql.execute(aql_query)\n",
    "        patient_conditions = [doc for doc in cursor]\n",
    "        \n",
    "        results[\"patient_data\"] = {\n",
    "            \"observations\": patient_observations,\n",
    "            \"conditions\": patient_conditions,\n",
    "            \"patient_id\": patient_id\n",
    "        }\n",
    "        \n",
    "        # Analyze based on analysis type\n",
    "        if analysis_type == \"evidence_path\":\n",
    "            # Find rarest condition if not specified\n",
    "            if \"condition_id\" not in metadata:\n",
    "                aql_query = f\"\"\"\n",
    "                FOR c IN conditions\n",
    "                    FILTER c.PATIENT == \"{patient_id}\"\n",
    "                    LET condition_count = (\n",
    "                        FOR c2 IN conditions\n",
    "                            FILTER c2.CODE == c.CODE\n",
    "                            COLLECT WITH COUNT INTO count\n",
    "                            RETURN count\n",
    "                    )\n",
    "                    SORT condition_count[0] ASC\n",
    "                    LIMIT 1\n",
    "                    RETURN {{\n",
    "                        code: c.CODE,\n",
    "                        description: c.DESCRIPTION,\n",
    "                        count: condition_count[0]\n",
    "                    }}\n",
    "                \"\"\"\n",
    "                cursor = db.aql.execute(aql_query)\n",
    "                rare_condition = [doc for doc in cursor][0] if cursor else None\n",
    "                \n",
    "                if rare_condition:\n",
    "                    metadata[\"condition_id\"] = rare_condition[\"code\"]\n",
    "            \n",
    "            # Create evidence path visualization\n",
    "            if \"condition_id\" in metadata:\n",
    "                condition_id = metadata[\"condition_id\"]\n",
    "                # Create a subgraph showing evidence path\n",
    "                G = nx.DiGraph()\n",
    "                \n",
    "                # Get condition information\n",
    "                condition_info = None\n",
    "                for c in patient_conditions:\n",
    "                    if str(c[\"code\"]) == str(condition_id):\n",
    "                        condition_info = c\n",
    "                        break\n",
    "                \n",
    "                if condition_info:\n",
    "                    # Add condition node\n",
    "                    G.add_node(f\"condition_{condition_info['code']}\", \n",
    "                              label=condition_info['description'],\n",
    "                              type=\"condition\",\n",
    "                              date=condition_info['start'])\n",
    "                    \n",
    "                    # Add observation nodes and edges\n",
    "                    for obs in patient_observations:\n",
    "                        if \"date\" in obs:\n",
    "                            G.add_node(f\"obs_{obs['code']}_{obs['date']}\", \n",
    "                                      label=obs['description'],\n",
    "                                      value=obs.get('value', 'N/A'),\n",
    "                                      type=\"observation\",\n",
    "                                      date=obs['date'])\n",
    "                            \n",
    "                            # Connect if observation came before diagnosis\n",
    "                            if obs['date'] <= condition_info['start']:\n",
    "                                G.add_edge(f\"obs_{obs['code']}_{obs['date']}\", \n",
    "                                          f\"condition_{condition_info['code']}\")\n",
    "                    \n",
    "                    # Store graph information\n",
    "                    results[\"evidence_path\"] = {\n",
    "                        \"condition\": condition_info,\n",
    "                        \"node_count\": len(G.nodes()),\n",
    "                        \"edge_count\": len(G.edges()),\n",
    "                        \"graph\": G\n",
    "                    }\n",
    "                \n",
    "        elif analysis_type == \"similar_cases\":\n",
    "            # Find similar patients with rare diseases\n",
    "            patient_obs_codes = [obs[\"code\"] for obs in patient_observations]\n",
    "            \n",
    "            # Get all patients and their observations\n",
    "            aql_query = f\"\"\"\n",
    "            LET all_patients = (\n",
    "                FOR p IN patients\n",
    "                    RETURN DISTINCT p._key\n",
    "            )\n",
    "            \n",
    "            FOR patient_id IN all_patients\n",
    "                LET patient_obs = (\n",
    "                    FOR obs IN observations\n",
    "                        FILTER obs.PATIENT == patient_id\n",
    "                        RETURN DISTINCT obs.CODE\n",
    "                )\n",
    "                \n",
    "                LET rare_conditions = (\n",
    "                    FOR c IN conditions\n",
    "                        FILTER c.PATIENT == patient_id\n",
    "                        // Count occurrences of this condition\n",
    "                        LET condition_count = (\n",
    "                            FOR c2 IN conditions\n",
    "                                FILTER c2.CODE == c.CODE\n",
    "                                COLLECT WITH COUNT INTO count\n",
    "                                RETURN count\n",
    "                        )\n",
    "                        // Only keep conditions in <5% of patients\n",
    "                        FILTER condition_count[0] <= 0.05 * LENGTH(all_patients)\n",
    "                        RETURN {{\n",
    "                            code: c.CODE,\n",
    "                            description: c.DESCRIPTION\n",
    "                        }}\n",
    "                )\n",
    "                \n",
    "                // Only include patients with rare conditions\n",
    "                FILTER LENGTH(rare_conditions) > 0\n",
    "                \n",
    "                // Calculate Jaccard similarity\n",
    "                LET jaccard_similarity = LENGTH(INTERSECTION(patient_obs, {patient_obs_codes})) / \n",
    "                                      LENGTH(UNION(patient_obs, {patient_obs_codes}))\n",
    "                                      \n",
    "                SORT jaccard_similarity DESC\n",
    "                LIMIT {metadata.get('top_k', 5) + 1}  // +1 for patient themselves\n",
    "                \n",
    "                RETURN {{\n",
    "                    patient_id: patient_id,\n",
    "                    similarity: jaccard_similarity,\n",
    "                    rare_conditions: rare_conditions,\n",
    "                    shared_observation_count: LENGTH(INTERSECTION(patient_obs, {patient_obs_codes})),\n",
    "                    total_observation_count: LENGTH(patient_obs)\n",
    "                }}\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor = db.aql.execute(aql_query)\n",
    "            similar_patients = [doc for doc in cursor]\n",
    "            \n",
    "            # Filter out query patient\n",
    "            similar_patients = [p for p in similar_patients if p['patient_id'] != patient_id][:metadata.get('top_k', 5)]\n",
    "            \n",
    "            results[\"similar_cases\"] = {\n",
    "                \"similar_patients\": similar_patients,\n",
    "                \"query_patient_id\": patient_id\n",
    "            }\n",
    "            \n",
    "        elif analysis_type == \"progression\":\n",
    "            # Analyze disease progression patterns\n",
    "            timeline = []\n",
    "            \n",
    "            # Add observations to timeline\n",
    "            for obs in patient_observations:\n",
    "                if \"date\" in obs:\n",
    "                    timeline.append({\n",
    "                        \"date\": obs[\"date\"],\n",
    "                        \"event_type\": \"observation\",\n",
    "                        \"description\": obs[\"description\"],\n",
    "                        \"code\": obs[\"code\"],\n",
    "                        \"value\": obs.get(\"value\", \"\")\n",
    "                    })\n",
    "            \n",
    "            # Add conditions to timeline\n",
    "            for cond in patient_conditions:\n",
    "                if \"start\" in cond:\n",
    "                    timeline.append({\n",
    "                        \"date\": cond[\"start\"],\n",
    "                        \"event_type\": \"condition_start\",\n",
    "                        \"description\": cond[\"description\"],\n",
    "                        \"code\": cond[\"code\"]\n",
    "                    })\n",
    "                \n",
    "                if \"stop\" in cond and cond[\"stop\"]:\n",
    "                    timeline.append({\n",
    "                        \"date\": cond[\"stop\"],\n",
    "                        \"event_type\": \"condition_end\",\n",
    "                        \"description\": cond[\"description\"],\n",
    "                        \"code\": cond[\"code\"]\n",
    "                    })\n",
    "            \n",
    "            # Sort timeline by date\n",
    "            timeline.sort(key=lambda x: x[\"date\"])\n",
    "            \n",
    "            results[\"progression_analysis\"] = {\n",
    "                \"timeline\": timeline,\n",
    "                \"patient_id\": patient_id\n",
    "            }\n",
    "        \n",
    "        else:  # Default to rare disease analysis\n",
    "            # Identify rare conditions for this patient\n",
    "            aql_query = f\"\"\"\n",
    "            LET all_patients = (\n",
    "                FOR p IN patients\n",
    "                    RETURN DISTINCT p._key\n",
    "            )\n",
    "            \n",
    "            FOR c IN conditions\n",
    "                FILTER c.PATIENT == \"{patient_id}\"\n",
    "                // Get count of this condition across patients\n",
    "                LET condition_count = (\n",
    "                    FOR c2 IN conditions\n",
    "                        FILTER c2.CODE == c.CODE\n",
    "                        COLLECT WITH COUNT INTO count\n",
    "                        RETURN count\n",
    "                )\n",
    "                // Calculate rarity\n",
    "                LET rarity = 1 - (condition_count[0] / LENGTH(all_patients))\n",
    "                // Only return rare conditions\n",
    "                FILTER rarity >= 0.9\n",
    "                SORT rarity DESC\n",
    "                RETURN {{\n",
    "                    code: c.CODE,\n",
    "                    description: c.DESCRIPTION,\n",
    "                    rarity: rarity,\n",
    "                    patient_count: condition_count[0],\n",
    "                    total_patients: LENGTH(all_patients)\n",
    "                }}\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor = db.aql.execute(aql_query)\n",
    "            rare_conditions = [doc for doc in cursor]\n",
    "            \n",
    "            results[\"rare_disease_analysis\"] = {\n",
    "                \"rare_conditions\": rare_conditions,\n",
    "                \"patient_id\": patient_id\n",
    "            }\n",
    "    \n",
    "    # Enhance results with LLM insights\n",
    "    analysis_prompt = f\"\"\"\n",
    "    I'm analyzing medical data for potential rare disease patterns:\n",
    "    \n",
    "    {results}\n",
    "    \n",
    "    Provide a clinical interpretation in the context of rare disease diagnosis.\n",
    "    Focus on:\n",
    "    1. Key patterns or insights\n",
    "    2. Potential rare disease indications\n",
    "    3. Suggested next steps for investigation\n",
    "    \n",
    "    Format as JSON with structured fields for different aspects.\n",
    "    \"\"\"\n",
    "    \n",
    "    analysis_result = llm.invoke(analysis_prompt).content\n",
    "    \n",
    "    try:\n",
    "        interpretation = json.loads(re.search(r'\\{.*\\}', analysis_result, re.DOTALL).group())\n",
    "        results[\"interpretation\"] = interpretation\n",
    "    except:\n",
    "        results[\"interpretation\"] = analysis_result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:42.917424Z",
     "iopub.status.busy": "2025-03-05T19:30:42.917073Z",
     "iopub.status.idle": "2025-03-05T19:30:42.927196Z",
     "shell.execute_reply": "2025-03-05T19:30:42.926375Z",
     "shell.execute_reply.started": "2025-03-05T19:30:42.917399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_medical_visualization(visualization_spec: dict):\n",
    "    \"\"\"\n",
    "    High-quality medical visualization generator that adapts to data type.\n",
    "    \n",
    "    Parameters:\n",
    "    - visualization_spec: A dictionary with:\n",
    "      - data: Data to visualize\n",
    "      - type: Visualization type (\"network\", \"timeline\", \"heatmap\", \"auto\")\n",
    "      - title: Title for the visualization\n",
    "      - context: Contextual information for visualization\n",
    "    \"\"\"\n",
    "    # Extract visualization specification\n",
    "    data = visualization_spec.get('data', {})\n",
    "    viz_type = visualization_spec.get('type', 'auto')\n",
    "    title = visualization_spec.get('title', 'Medical Data Visualization')\n",
    "    context = visualization_spec.get('context', {})\n",
    "    \n",
    "    # Determine best visualization if auto\n",
    "    if viz_type == 'auto':\n",
    "        if isinstance(data, nx.Graph) or 'graph' in data or ('nodes' in data and 'edges' in data):\n",
    "            viz_type = 'network'\n",
    "        elif 'timeline' in data or any('date' in str(item) for item in data):\n",
    "            viz_type = 'timeline'\n",
    "        elif 'matrix' in data or 'heatmap' in data:\n",
    "            viz_type = 'heatmap'\n",
    "        else:\n",
    "            viz_type = 'network'  # Default for medical data\n",
    "    \n",
    "    # Create appropriate visualization\n",
    "    if viz_type == 'network':\n",
    "        return create_network_visualization(data, title, context)\n",
    "    elif viz_type == 'timeline':\n",
    "        return create_timeline_visualization(data, title, context)\n",
    "    elif viz_type == 'heatmap':\n",
    "        return create_heatmap_visualization(data, title, context)\n",
    "    elif viz_type == 'sankey':\n",
    "        return create_sankey_visualization(data, title, context)\n",
    "    else:\n",
    "        return {\"error\": f\"Unsupported visualization type: {viz_type}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:48.500455Z",
     "iopub.status.busy": "2025-03-05T19:30:48.500008Z",
     "iopub.status.idle": "2025-03-05T19:30:48.537350Z",
     "shell.execute_reply": "2025-03-05T19:30:48.536463Z",
     "shell.execute_reply.started": "2025-03-05T19:30:48.500411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def create_network_visualization(data, title, context):\n",
    "    \"\"\"Create network visualization using Matplotlib instead of Plotly\"\"\"\n",
    "    # Extract or create graph structure\n",
    "    if isinstance(data, nx.Graph):\n",
    "        G = data\n",
    "    elif 'graph' in data and isinstance(data['graph'], nx.Graph):\n",
    "        G = data['graph']\n",
    "    elif 'nodes' in data and 'edges' in data:\n",
    "        G = nx.Graph()\n",
    "        for node in data['nodes']:\n",
    "            G.add_node(node['id'], **{k: v for k, v in node.items() if k != 'id'})\n",
    "        for edge in data['edges']:\n",
    "            G.add_edge(edge['source'], edge['target'], **{k: v for k, v in edge.items() \n",
    "                                                       if k not in ['source', 'target']})\n",
    "    else:\n",
    "        # Create a default medical knowledge graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add some nodes and edges based on context\n",
    "        condition = context.get('condition', 'Unknown Condition')\n",
    "        G.add_node('condition', label=condition, type='condition')\n",
    "        \n",
    "        symptoms = context.get('symptoms', ['Symptom 1', 'Symptom 2', 'Symptom 3'])\n",
    "        for i, symptom in enumerate(symptoms):\n",
    "            G.add_node(f'symptom_{i}', label=symptom, type='symptom')\n",
    "            G.add_edge(f'symptom_{i}', 'condition', type='indicates')\n",
    "    \n",
    "    # Get positions for nodes using spring layout\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Map node types to colors\n",
    "    color_map = {\n",
    "        'condition': 'red',\n",
    "        'symptom': 'blue',\n",
    "        'observation': 'blue',\n",
    "        'medication': 'green',\n",
    "        'procedure': 'purple',\n",
    "        'allergy': 'orange',\n",
    "        'patient': 'yellow',\n",
    "        'unknown': 'gray'\n",
    "    }\n",
    "    \n",
    "    # Group nodes by type for better visualization\n",
    "    node_types = {}\n",
    "    for node in G.nodes():\n",
    "        node_type = G.nodes[node].get('type', 'unknown')\n",
    "        if node_type not in node_types:\n",
    "            node_types[node_type] = []\n",
    "        node_types[node_type].append(node)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, edge_color='gray')\n",
    "    \n",
    "    # Draw nodes by type with different colors\n",
    "    for node_type, nodes in node_types.items():\n",
    "        color = color_map.get(node_type, 'gray')\n",
    "        nx.draw_networkx_nodes(G, pos, \n",
    "                              nodelist=nodes, \n",
    "                              node_color=color,\n",
    "                              node_size=500,\n",
    "                              alpha=0.8,\n",
    "                              label=node_type)\n",
    "    \n",
    "    # Add labels\n",
    "    node_labels = {}\n",
    "    for node in G.nodes():\n",
    "        if 'label' in G.nodes[node]:\n",
    "            node_labels[node] = G.nodes[node]['label']\n",
    "        else:\n",
    "            node_labels[node] = str(node)\n",
    "    \n",
    "    nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10, font_color='black')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add title and remove axes\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Save visualization to file\n",
    "    img_path = f\"{title.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        \"image_path\": img_path,\n",
    "        \"node_count\": len(G.nodes()),\n",
    "        \"edge_count\": len(G.edges()),\n",
    "        \"visualization_type\": \"network\"\n",
    "    }\n",
    "def create_timeline_visualization(data, title, context):\n",
    "    \"\"\"Create interactive timeline visualization for disease progression\"\"\"\n",
    "    # Extract timeline data\n",
    "    if 'timeline' in data:\n",
    "        timeline_data = data['timeline']\n",
    "    else:\n",
    "        timeline_data = data\n",
    "    \n",
    "    # Ensure timeline_data is a list\n",
    "    if not isinstance(timeline_data, list):\n",
    "        return {\"error\": \"Timeline data must be a list of events\"}\n",
    "    \n",
    "    # Sort timeline by date if not already sorted\n",
    "    timeline_data.sort(key=lambda x: x.get('date', ''))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame(timeline_data)\n",
    "    \n",
    "    # If dataframe doesn't have certain columns, add defaults\n",
    "    if 'date' not in df.columns:\n",
    "        return {\"error\": \"Timeline data must contain 'date' field\"}\n",
    "    \n",
    "    if 'event_type' not in df.columns:\n",
    "        df['event_type'] = 'event'\n",
    "        \n",
    "    if 'description' not in df.columns:\n",
    "        df['description'] = 'Unknown event'\n",
    "    \n",
    "    # Map event types to colors\n",
    "    color_map = {\n",
    "        'condition_start': 'red',\n",
    "        'condition_end': 'orange',\n",
    "        'observation': 'blue',\n",
    "        'medication_start': 'green',\n",
    "        'medication_end': 'lightgreen',\n",
    "        'procedure': 'purple',\n",
    "        'event': 'gray'\n",
    "    }\n",
    "    \n",
    "    # Create interactive timeline using Plotly\n",
    "    fig = px.scatter(df, x='date', y='event_type', \n",
    "                   color='event_type', hover_name='description',\n",
    "                   color_discrete_map=color_map,\n",
    "                   title=title)\n",
    "    \n",
    "    # Add details to hover\n",
    "    hover_template = \"<b>%{hovertext}</b><br>Date: %{x}<br>Type: %{y}<br>\"\n",
    "    if 'value' in df.columns:\n",
    "        hover_template += \"Value: %{customdata}<br>\"\n",
    "        fig.update_traces(customdata=df['value'])\n",
    "    if 'code' in df.columns:\n",
    "        hover_template += \"Code: %{customdata}<br>\"\n",
    "        fig.update_traces(customdata=df['code'])\n",
    "        \n",
    "    fig.update_traces(hovertemplate=hover_template)\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Event Type\",\n",
    "        legend_title=\"Event Type\",\n",
    "        template=\"plotly_white\",\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Add connecting lines for progression\n",
    "    fig.update_layout(\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                xref=\"x\", yref=\"paper\",\n",
    "                x0=df['date'][i], y0=0, \n",
    "                x1=df['date'][i], y1=1,\n",
    "                line=dict(\n",
    "                    color=\"Gray\",\n",
    "                    width=1,\n",
    "                    dash=\"dot\",\n",
    "                )\n",
    "            )\n",
    "            for i in range(len(df))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Save visualization to HTML file\n",
    "    output_path = f\"{title.replace(' ', '_').lower()}.html\"\n",
    "    fig.write_html(output_path)\n",
    "    \n",
    "    # Also save a static image\n",
    "    img_path = f\"{title.replace(' ', '_').lower()}.png\"\n",
    "    fig.write_image(img_path)\n",
    "    \n",
    "    return {\n",
    "        \"visualization_path\": output_path,\n",
    "        \"image_path\": img_path,\n",
    "        \"event_count\": len(timeline_data),\n",
    "        \"visualization_type\": \"timeline\"\n",
    "    }\n",
    "\n",
    "def create_heatmap_visualization(data, title, context):\n",
    "    \"\"\"Create heatmap visualization for symptom-disease relationships\"\"\"\n",
    "    # Extract heatmap data\n",
    "    if 'matrix' in data:\n",
    "        matrix_data = data['matrix']\n",
    "        row_labels = data.get('row_labels', [])\n",
    "        col_labels = data.get('col_labels', [])\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        matrix_data = data.values\n",
    "        row_labels = data.index.tolist()\n",
    "        col_labels = data.columns.tolist()\n",
    "    else:\n",
    "        # Try to construct a heatmap from available data\n",
    "        matrix_data = []\n",
    "        row_labels = []\n",
    "        col_labels = []\n",
    "        \n",
    "        # This is a fallback if proper matrix data isn't provided\n",
    "        if context.get('symptoms') and context.get('conditions'):\n",
    "            symptoms = context.get('symptoms', [])\n",
    "            conditions = context.get('conditions', [])\n",
    "            \n",
    "            # Create an empty matrix\n",
    "            matrix_data = np.zeros((len(symptoms), len(conditions)))\n",
    "            row_labels = symptoms\n",
    "            col_labels = conditions\n",
    "            \n",
    "            # Fill with random data as placeholder\n",
    "            for i in range(len(symptoms)):\n",
    "                for j in range(len(conditions)):\n",
    "                    matrix_data[i][j] = np.random.random()\n",
    "        else:\n",
    "            # Complete fallback with placeholder data\n",
    "            symptoms = [\"Symptom 1\", \"Symptom 2\", \"Symptom 3\", \"Symptom 4\", \"Symptom 5\"]\n",
    "            conditions = [\"Disease A\", \"Disease B\", \"Disease C\", \"Disease D\", \"Disease E\"]\n",
    "            \n",
    "            matrix_data = np.random.rand(len(symptoms), len(conditions))\n",
    "            row_labels = symptoms\n",
    "            col_labels = conditions\n",
    "    \n",
    "    # Create heatmap visualization using Plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=matrix_data,\n",
    "        x=col_labels,\n",
    "        y=row_labels,\n",
    "        colorscale='Blues',\n",
    "        hovertemplate='%{y}  %{x}: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis=dict(title='Conditions'),\n",
    "        yaxis=dict(title='Symptoms'),\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    # Save visualization to HTML file\n",
    "    output_path = f\"{title.replace(' ', '_').lower()}.html\"\n",
    "    fig.write_html(output_path)\n",
    "    \n",
    "    # Also save a static image\n",
    "    img_path = f\"{title.replace(' ', '_').lower()}.png\"\n",
    "    fig.write_image(img_path)\n",
    "    \n",
    "    return {\n",
    "        \"visualization_path\": output_path,\n",
    "        \"image_path\": img_path,\n",
    "        \"matrix_dimensions\": f\"{len(matrix_data)}x{len(matrix_data[0]) if matrix_data else 0}\",\n",
    "        \"visualization_type\": \"heatmap\"\n",
    "    }\n",
    "\n",
    "def create_sankey_visualization(data, title, context):\n",
    "    \"\"\"Create Sankey diagram for patient pathways or disease progression\"\"\"\n",
    "    # Prepare data for Sankey diagram\n",
    "    if 'links' in data and 'nodes' in data:\n",
    "        links = data['links']\n",
    "        nodes = data['nodes']\n",
    "    else:\n",
    "        # Try to construct from pathway data if available\n",
    "        links = []\n",
    "        nodes = []\n",
    "        node_ids = {}\n",
    "        \n",
    "        # Extract pathway data\n",
    "        pathways = data.get('pathways', [])\n",
    "        if not pathways and 'timeline' in data:\n",
    "            # Convert timeline to pathways\n",
    "            events = data['timeline']\n",
    "            events.sort(key=lambda x: x.get('date', ''))\n",
    "            \n",
    "            # Group by patient if applicable\n",
    "            patient_id = context.get('patient_id', 'unknown')\n",
    "            pathways = [{\n",
    "                'patient_id': patient_id,\n",
    "                'events': events\n",
    "            }]\n",
    "        \n",
    "        # Create nodes and links from pathways\n",
    "        node_counter = 0\n",
    "        for pathway in pathways:\n",
    "            events = pathway.get('events', [])\n",
    "            \n",
    "            # Add nodes for each unique event\n",
    "            for event in events:\n",
    "                event_type = event.get('event_type', 'event')\n",
    "                description = event.get('description', 'Unknown')\n",
    "                \n",
    "                # Create a unique node identifier\n",
    "                node_id = f\"{event_type}_{description}\"\n",
    "                \n",
    "                if node_id not in node_ids:\n",
    "                    node_ids[node_id] = node_counter\n",
    "                    nodes.append({\n",
    "                        'id': node_counter,\n",
    "                        'name': description,\n",
    "                        'type': event_type\n",
    "                    })\n",
    "                    node_counter += 1\n",
    "            \n",
    "            # Add links between sequential events\n",
    "            for i in range(len(events) - 1):\n",
    "                source_event = events[i]\n",
    "                target_event = events[i + 1]\n",
    "                \n",
    "                source_id = node_ids[f\"{source_event.get('event_type', 'event')}_{source_event.get('description', 'Unknown')}\"]\n",
    "                target_id = node_ids[f\"{target_event.get('event_type', 'event')}_{target_event.get('description', 'Unknown')}\"]\n",
    "                \n",
    "                # Check if link already exists and increment value if so\n",
    "                link_exists = False\n",
    "                for link in links:\n",
    "                    if link['source'] == source_id and link['target'] == target_id:\n",
    "                        link['value'] += 1\n",
    "                        link_exists = True\n",
    "                        break\n",
    "                \n",
    "                if not link_exists:\n",
    "                    links.append({\n",
    "                        'source': source_id,\n",
    "                        'target': target_id,\n",
    "                        'value': 1\n",
    "                    })\n",
    "    \n",
    "    # Create Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=[node.get('name', f\"Node {node['id']}\") for node in nodes],\n",
    "            color=[get_color_for_type(node.get('type', 'unknown')) for node in nodes]\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=[link['source'] for link in links],\n",
    "            target=[link['target'] for link in links],\n",
    "            value=[link['value'] for link in links]\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        font=dict(size=12),\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    # Save visualization to HTML file\n",
    "    output_path = f\"{title.replace(' ', '_').lower()}.html\"\n",
    "    fig.write_html(output_path)\n",
    "    \n",
    "    # Also save a static image\n",
    "    img_path = f\"{title.replace(' ', '_').lower()}.png\"\n",
    "    fig.write_image(img_path)\n",
    "    \n",
    "    return {\n",
    "        \"visualization_path\": output_path,\n",
    "        \"image_path\": img_path,\n",
    "        \"node_count\": len(nodes),\n",
    "        \"link_count\": len(links),\n",
    "        \"visualization_type\": \"sankey\"\n",
    "    }\n",
    "\n",
    "def get_color_for_type(event_type):\n",
    "    \"\"\"Helper function to get colors based on event type\"\"\"\n",
    "    color_map = {\n",
    "        'condition': 'rgba(255, 0, 0, 0.8)',\n",
    "        'condition_start': 'rgba(255, 0, 0, 0.8)',\n",
    "        'condition_end': 'rgba(255, 150, 0, 0.8)',\n",
    "        'observation': 'rgba(0, 0, 255, 0.8)',\n",
    "        'medication': 'rgba(0, 128, 0, 0.8)',\n",
    "        'medication_start': 'rgba(0, 128, 0, 0.8)',\n",
    "        'medication_end': 'rgba(144, 238, 144, 0.8)',\n",
    "        'procedure': 'rgba(128, 0, 128, 0.8)',\n",
    "        'symptom': 'rgba(0, 191, 255, 0.8)',\n",
    "        'allergy': 'rgba(255, 165, 0, 0.8)',\n",
    "        'patient': 'rgba(255, 255, 0, 0.8)',\n",
    "        'event': 'rgba(128, 128, 128, 0.8)',\n",
    "        'unknown': 'rgba(128, 128, 128, 0.8)'\n",
    "    }\n",
    "    return color_map.get(event_type.lower(), 'rgba(128, 128, 128, 0.8)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:56.815616Z",
     "iopub.status.busy": "2025-03-05T19:30:56.815337Z",
     "iopub.status.idle": "2025-03-05T19:30:56.819514Z",
     "shell.execute_reply": "2025-03-05T19:30:56.818693Z",
     "shell.execute_reply.started": "2025-03-05T19:30:56.815595Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_rare_disease_agent():\n",
    "    \"\"\"Create an agent with the custom medical tools\"\"\"\n",
    "    tools = [\n",
    "        query_medical_graph,\n",
    "        analyze_patient_symptoms,\n",
    "        generate_medical_visualization\n",
    "    ]\n",
    "    \n",
    "    # Create the agent with LangGraph\n",
    "    agent = create_react_agent(\n",
    "        llm, \n",
    "        tools\n",
    "    )\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:30:59.170052Z",
     "iopub.status.busy": "2025-03-05T19:30:59.169639Z",
     "iopub.status.idle": "2025-03-05T19:30:59.188392Z",
     "shell.execute_reply": "2025-03-05T19:30:59.187655Z",
     "shell.execute_reply.started": "2025-03-05T19:30:59.170011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rare_disease_agent = create_rare_disease_agent()\n",
    "\n",
    "# Define helper functions to query the agent\n",
    "def query_graph(query):\n",
    "    \"\"\"Run a query through the medical graph agent\"\"\"\n",
    "    response = rare_disease_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:31:03.657621Z",
     "iopub.status.busy": "2025-03-05T19:31:03.657326Z",
     "iopub.status.idle": "2025-03-05T19:31:03.679655Z",
     "shell.execute_reply": "2025-03-05T19:31:03.678864Z",
     "shell.execute_reply.started": "2025-03-05T19:31:03.657599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dashboard():\n",
    "    \"\"\"Create an interactive dashboard for medical graph exploration\"\"\"\n",
    "    # Create main layout\n",
    "    header = widgets.HTML(\"\"\"\n",
    "    <div style=\"background-color: #1A5276; color: white; padding: 20px; border-radius: 5px; margin-bottom: 20px;\">\n",
    "        <h1 style=\"margin: 0;\">MedGraph Explorer</h1>\n",
    "        <p>Interactive Medical Graph Analysis for Rare Disease Patterns</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create tabs\n",
    "    tabs = widgets.Tab()\n",
    "    \n",
    "    # Tab 1: Query Explorer\n",
    "    query_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter your medical query here...',\n",
    "        description='Query:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%', height='100px')\n",
    "    )\n",
    "    \n",
    "    query_type = widgets.RadioButtons(\n",
    "        options=['Auto', 'AQL', 'NetworkX', 'Hybrid'],\n",
    "        value='Auto',\n",
    "        description='Query Type:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    example_queries = widgets.Dropdown(\n",
    "        options=[\n",
    "            'What are the most common symptoms of autoimmune disorders?',\n",
    "            'Find patients with rare conditions and analyze their symptom patterns',\n",
    "            'Identify clusters of patients with similar rare disease profiles',\n",
    "            'Show the progression timeline for patients with lupus',\n",
    "            'Visualize the relationship between diabetes and heart disease',\n",
    "            'What are the most common comorbidities for rare diseases?'\n",
    "        ],\n",
    "        description='Examples:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Run Query',\n",
    "        button_style='primary',\n",
    "        tooltip='Click to run query',\n",
    "        icon='search'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    # Tab 2: Patient Explorer\n",
    "    patient_id_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter patient ID',\n",
    "        description='Patient ID:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    analysis_type = widgets.Dropdown(\n",
    "        options=['rare_disease', 'evidence_path', 'similar_cases', 'progression'],\n",
    "        value='rare_disease',\n",
    "        description='Analysis:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    run_patient_button = widgets.Button(\n",
    "        description='Analyze Patient',\n",
    "        button_style='primary',\n",
    "        tooltip='Click to analyze patient',\n",
    "        icon='user'\n",
    "    )\n",
    "    \n",
    "    patient_output = widgets.Output()\n",
    "    \n",
    "    # Tab 3: Visualization Explorer\n",
    "    viz_type = widgets.Dropdown(\n",
    "        options=['network', 'timeline', 'heatmap', 'sankey', 'auto'],\n",
    "        value='auto',\n",
    "        description='Viz Type:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    viz_title = widgets.Text(\n",
    "        value='Medical Data Visualization',\n",
    "        description='Title:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    viz_data_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter JSON data for visualization or leave empty to use last query results',\n",
    "        description='Data (optional):',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%', height='100px')\n",
    "    )\n",
    "    \n",
    "    run_viz_button = widgets.Button(\n",
    "        description='Generate Visualization',\n",
    "        button_style='primary',\n",
    "        tooltip='Click to generate visualization',\n",
    "        icon='chart-line'\n",
    "    )\n",
    "    \n",
    "    viz_output = widgets.Output()\n",
    "    \n",
    "    # Tab 4: About & Help\n",
    "    about_content = widgets.HTML(\"\"\"\n",
    "    <div style=\"padding: 20px; background-color: #f8f9fa; border-radius: 5px;\">\n",
    "        <h2>About MedGraph Explorer</h2>\n",
    "        <p>This tool enables advanced exploration of medical data using graph analytics and AI to identify rare disease patterns.</p>\n",
    "        \n",
    "        <h3>Features:</h3>\n",
    "        <ul>\n",
    "            <li><strong>Intelligent Query Processing:</strong> Natural language queries with automatic selection of AQL or graph algorithms</li>\n",
    "            <li><strong>Patient Analysis:</strong> Examine individual patients for rare conditions and symptom patterns</li>\n",
    "            <li><strong>Interactive Visualizations:</strong> Network graphs, timelines, and heatmaps for medical insights</li>\n",
    "            <li><strong>GPU Acceleration:</strong> Leverages NVIDIA cuGraph when available for high-performance analytics</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h3>How to Use:</h3>\n",
    "        <ol>\n",
    "            <li>Enter a natural language query about medical data in the <strong>Query Explorer</strong> tab</li>\n",
    "            <li>Analyze specific patients using the <strong>Patient Explorer</strong> tab</li>\n",
    "            <li>Create custom visualizations in the <strong>Visualization Explorer</strong> tab</li>\n",
    "        </ol>\n",
    "        \n",
    "        <h3>Example Queries:</h3>\n",
    "        <ul>\n",
    "            <li>\"What are the most common initial symptoms for rare autoimmune disorders?\"</li>\n",
    "            <li>\"Find clusters of patients with similar rare disease progression\"</li>\n",
    "            <li>\"Visualize the relationship between symptoms X and condition Y\"</li>\n",
    "        </ul>\n",
    "        \n",
    "        <p><em>Developed for the ArangoDB GraphRAG & NVIDIA cuGraph Hackathon</em></p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # Assemble tabs\n",
    "    query_tab = widgets.VBox([\n",
    "        example_queries,\n",
    "        query_input,\n",
    "        widgets.HBox([query_type, run_button]),\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        widgets.HTML(\"<h3>Results:</h3>\"),\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    patient_tab = widgets.VBox([\n",
    "        widgets.HBox([patient_id_input, analysis_type]),\n",
    "        run_patient_button,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        widgets.HTML(\"<h3>Patient Analysis:</h3>\"),\n",
    "        patient_output\n",
    "    ])\n",
    "    \n",
    "    viz_tab = widgets.VBox([\n",
    "        widgets.HBox([viz_type, viz_title]),\n",
    "        viz_data_input,\n",
    "        run_viz_button,\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        widgets.HTML(\"<h3>Visualization:</h3>\"),\n",
    "        viz_output\n",
    "    ])\n",
    "    \n",
    "    about_tab = widgets.VBox([about_content])\n",
    "    \n",
    "    # Set up tabs\n",
    "    tabs.children = [query_tab, patient_tab, viz_tab, about_tab]\n",
    "    tabs.set_title(0, 'Query Explorer')\n",
    "    tabs.set_title(1, 'Patient Explorer')\n",
    "    tabs.set_title(2, 'Visualization')\n",
    "    tabs.set_title(3, 'About & Help')\n",
    "    \n",
    "    # Store for results for later use\n",
    "    latest_results = {'query': None, 'patient': None, 'viz': None}\n",
    "    \n",
    "    # Set up event handlers\n",
    "    def on_example_select(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            query_input.value = change['new']\n",
    "    \n",
    "    def on_run_button_click(b):\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(f\"Running query: {query_input.value}\")\n",
    "            print(f\"Analysis type: {query_type.value}\")\n",
    "            print(\"Processing...\")\n",
    "            \n",
    "            # Prepare query parameters\n",
    "            query_params = {\n",
    "                'query': query_input.value,\n",
    "                'approach': None if query_type.value == 'Auto' else query_type.value.lower()\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Run query through agent\n",
    "                result = rare_disease_agent.invoke({\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": f\"Query the medical graph: {json.dumps(query_params)}\"\n",
    "                    }]\n",
    "                })\n",
    "                \n",
    "                # Store result for later use\n",
    "                latest_results['query'] = result[\"messages\"][-1].content\n",
    "                \n",
    "                # Display result\n",
    "                clear_output()\n",
    "                display(HTML(f\"<h3>Query Results:</h3><p>{result['messages'][-1].content}</p>\"))\n",
    "                \n",
    "                # Try to extract and display visualization if available\n",
    "                try:\n",
    "                    result_text = result[\"messages\"][-1].content\n",
    "                    if \"visualization_path\" in result_text:\n",
    "                        viz_path_match = re.search(r'\"visualization_path\":\\s*\"([^\"]+)\"', result_text)\n",
    "                        if viz_path_match and os.path.exists(viz_path_match.group(1)):\n",
    "                            viz_path = viz_path_match.group(1)\n",
    "                            if viz_path.endswith('.html'):\n",
    "                                display(HTML(f'<iframe src=\"{viz_path}\" width=\"100%\" height=\"600px\"></iframe>'))\n",
    "                            else:\n",
    "                                display(HTML(f'<img src=\"{viz_path}\" style=\"max-width:100%;\">'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error displaying visualization: {e}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                clear_output()\n",
    "                print(f\"Error running query: {e}\")\n",
    "    \n",
    "    def on_run_patient_button_click(b):\n",
    "        with patient_output:\n",
    "            clear_output()\n",
    "            \n",
    "            patient_id = patient_id_input.value.strip()\n",
    "            if not patient_id:\n",
    "                print(\"Please enter a valid patient ID\")\n",
    "                return\n",
    "            \n",
    "            print(f\"Analyzing patient: {patient_id}\")\n",
    "            print(f\"Analysis type: {analysis_type.value}\")\n",
    "            print(\"Processing...\")\n",
    "            \n",
    "            # Prepare patient analysis parameters\n",
    "            patient_params = {\n",
    "                'patient_id': patient_id,\n",
    "                'analysis_type': analysis_type.value\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Run patient analysis through agent\n",
    "                result = rare_disease_agent.invoke({\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": f\"Analyze patient symptoms: {json.dumps(patient_params)}\"\n",
    "                    }]\n",
    "                })\n",
    "                \n",
    "                # Store result for later use\n",
    "                latest_results['patient'] = result[\"messages\"][-1].content\n",
    "                \n",
    "                # Display result\n",
    "                clear_output()\n",
    "                display(HTML(f\"<h3>Patient Analysis:</h3><p>{result['messages'][-1].content}</p>\"))\n",
    "                \n",
    "                # Try to extract and display visualization if available\n",
    "                try:\n",
    "                    result_text = result[\"messages\"][-1].content\n",
    "                    if \"visualization_path\" in result_text or \"image_path\" in result_text:\n",
    "                        viz_path_match = re.search(r'\"(visualization_path|image_path)\":\\s*\"([^\"]+)\"', result_text)\n",
    "                        if viz_path_match and os.path.exists(viz_path_match.group(2)):\n",
    "                            viz_path = viz_path_match.group(2)\n",
    "                            if viz_path.endswith('.html'):\n",
    "                                display(HTML(f'<iframe src=\"{viz_path}\" width=\"100%\" height=\"600px\"></iframe>'))\n",
    "                            else:\n",
    "                                display(HTML(f'<img src=\"{viz_path}\" style=\"max-width:100%;\">'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error displaying visualization: {e}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                clear_output()\n",
    "                print(f\"Error analyzing patient: {e}\")\n",
    "    \n",
    "    def on_run_viz_button_click(b):\n",
    "        with viz_output:\n",
    "            clear_output()\n",
    "            \n",
    "            print(f\"Generating visualization: {viz_title.value}\")\n",
    "            print(f\"Visualization type: {viz_type.value}\")\n",
    "            print(\"Processing...\")\n",
    "            \n",
    "            # Prepare visualization parameters\n",
    "            viz_params = {\n",
    "                'type': viz_type.value,\n",
    "                'title': viz_title.value\n",
    "            }\n",
    "            \n",
    "            # Use provided data or last query results\n",
    "            if viz_data_input.value.strip():\n",
    "                try:\n",
    "                    viz_params['data'] = json.loads(viz_data_input.value)\n",
    "                except:\n",
    "                    clear_output()\n",
    "                    print(\"Error: Invalid JSON data\")\n",
    "                    return\n",
    "            else:\n",
    "                # Use most recent results\n",
    "                viz_params['data'] = {\n",
    "                    'latest_query': latest_results['query'],\n",
    "                    'latest_patient': latest_results['patient'],\n",
    "                    'latest_viz': latest_results['viz']\n",
    "                }\n",
    "            \n",
    "            try:\n",
    "                # Generate visualization through agent\n",
    "                result = rare_disease_agent.invoke({\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": f\"Generate medical visualization: {json.dumps(viz_params)}\"\n",
    "                    }]\n",
    "                })\n",
    "                \n",
    "                # Store result for later use\n",
    "                latest_results['viz'] = result[\"messages\"][-1].content\n",
    "                \n",
    "                # Display result\n",
    "                clear_output()\n",
    "                display(HTML(f\"<h3>Visualization:</h3><p>{result['messages'][-1].content}</p>\"))\n",
    "                \n",
    "                # Try to extract and display visualization\n",
    "                try:\n",
    "                    result_text = result[\"messages\"][-1].content\n",
    "                    if \"visualization_path\" in result_text or \"image_path\" in result_text:\n",
    "                        viz_path_match = re.search(r'\"(visualization_path|image_path)\":\\s*\"([^\"]+)\"', result_text)\n",
    "                        if viz_path_match and os.path.exists(viz_path_match.group(2)):\n",
    "                            viz_path = viz_path_match.group(2)\n",
    "                            if viz_path.endswith('.html'):\n",
    "                                display(HTML(f'<iframe src=\"{viz_path}\" width=\"100%\" height=\"600px\"></iframe>'))\n",
    "                            else:\n",
    "                                display(HTML(f'<img src=\"{viz_path}\" style=\"max-width:100%;\">'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error displaying visualization: {e}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                clear_output()\n",
    "                print(f\"Error generating visualization: {e}\")\n",
    "    \n",
    "    # Connect event handlers\n",
    "    example_queries.observe(on_example_select, names='value')\n",
    "    run_button.on_click(on_run_button_click)\n",
    "    run_patient_button.on_click(on_run_patient_button_click)\n",
    "    run_viz_button.on_click(on_run_viz_button_click)\n",
    "    \n",
    "    # Assemble dashboard\n",
    "    dashboard = widgets.VBox([header, tabs])\n",
    "    return dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:31:18.526702Z",
     "iopub.status.busy": "2025-03-05T19:31:18.526367Z",
     "iopub.status.idle": "2025-03-05T19:31:18.595259Z",
     "shell.execute_reply": "2025-03-05T19:31:18.594296Z",
     "shell.execute_reply.started": "2025-03-05T19:31:18.526661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dashboard = create_dashboard()\n",
    "display(dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:31:07.563857Z",
     "iopub.status.busy": "2025-03-05T19:31:07.563565Z",
     "iopub.status.idle": "2025-03-05T19:31:07.569986Z",
     "shell.execute_reply": "2025-03-05T19:31:07.568993Z",
     "shell.execute_reply.started": "2025-03-05T19:31:07.563835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_visualization_directly(viz_spec):\n",
    "    \"\"\"Helper function to call the visualization tool directly without tool validation\"\"\"\n",
    "    data = viz_spec.get('data', {})\n",
    "    viz_type = viz_spec.get('type', 'auto')\n",
    "    title = viz_spec.get('title', 'Medical Data Visualization')\n",
    "    context = viz_spec.get('context', {})\n",
    "    \n",
    "    # Determine best visualization if auto\n",
    "    if viz_type == 'auto':\n",
    "        if isinstance(data, nx.Graph) or 'graph' in data or ('nodes' in data and 'edges' in data):\n",
    "            viz_type = 'network'\n",
    "        elif 'timeline' in data or any('date' in str(item) for item in data):\n",
    "            viz_type = 'timeline'\n",
    "        elif 'matrix' in data or 'heatmap' in data:\n",
    "            viz_type = 'heatmap'\n",
    "        else:\n",
    "            viz_type = 'network'  # Default for medical data\n",
    "    \n",
    "    # Create appropriate visualization\n",
    "    if viz_type == 'network':\n",
    "        return create_network_visualization(data, title, context)\n",
    "    elif viz_type == 'timeline':\n",
    "        # Fallback to simple timeline if needed\n",
    "        try:\n",
    "            return create_timeline_visualization(data, title, context)\n",
    "        except:\n",
    "            return {\"error\": \"Timeline visualization failed. Try using a simpler format.\"}\n",
    "    elif viz_type == 'heatmap':\n",
    "        # Fallback to simple heatmap if needed\n",
    "        try:\n",
    "            return create_heatmap_visualization(data, title, context)\n",
    "        except:\n",
    "            return {\"error\": \"Heatmap visualization failed. Try using a simpler format.\"}\n",
    "    else:\n",
    "        return {\"error\": f\"Unsupported visualization type: {viz_type}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T19:31:10.475034Z",
     "iopub.status.busy": "2025-03-05T19:31:10.474614Z",
     "iopub.status.idle": "2025-03-05T19:31:11.010662Z",
     "shell.execute_reply": "2025-03-05T19:31:11.009759Z",
     "shell.execute_reply.started": "2025-03-05T19:31:10.474995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "viz_spec = {\n",
    "    \"type\": \"network\",\n",
    "    \"title\": \"Rare Disease Relationship Network\",\n",
    "    \"context\": {\n",
    "        \"condition\": \"Rare Autoimmune Disorder\",\n",
    "        \"symptoms\": [\"Joint Pain\", \"Fatigue\", \"Rash\", \"Fever\", \"Weight Loss\"]\n",
    "    }\n",
    "}\n",
    "visualization_result = generate_visualization_directly(viz_spec)\n",
    "print(json.dumps(visualization_result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
